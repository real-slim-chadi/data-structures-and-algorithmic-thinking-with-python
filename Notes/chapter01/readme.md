# Introduction
This is a **VERY** comprehensive introduction. Thank you.
## Variables
We can understand them as "names" that we put on numbers.
## Data Types
"a data type is a set ofo predefined values [for a variable]".

It's a way for programming languages to transform 0s and 1s into human readable values.

Examples: integer, noating point, unit number, character, string, etc.

### Primitive data Types
The programming language comes built in with many data types.

We use the built in data types to make more data types (will see this through the book)

### User Defined Data Types
users can define data types of their own , for specific usage.

## Data structures:
Here is where things get (more) interesting:

A data structure is a way to store data inside a computer. Some allow fast access, others allow fast storage.

As they say: There are many tastes for the same cake. Similarly, there are many data structures to be implemented on the same data.

## Abstract data types (ADT)
Usually data structures need specific operations.

The ADT is a collection of both:
1. Declaration of data
2. Declaration of operations

Ex: stack and LIFO

## What is an algorithm
An algorithm is a collection of steps
##  Why do we analyse algorithms?
Algorithm analysis helps us determine which algorithm to implement.
- There are Many ways to do the same thing
  - Some are Better than others
- Algorithm analysis helps us determine which algorithm to implement.

## Goal of Algorithm Analysis
Restated: **compare many characteristics about an algorithm** with other algorithms.
## What is time analysis ?
one of the characteristics we care about in an algorithm is how long it takes for us to run it.

key term: **Time complexity**

The time depends on the inpput. Examples of things we care about:
- Size of an array
- Polynomial degree
- Number of elements in a matrix
- Number of bits in the binary representation of the input Vertices
- edges in a graph

## How to compare?
we need to define **objective** measures.

usually we measure the 'rate of growth' of the time needed by the algorithm wrt the size of the input.

Basically it's _f(N)_
